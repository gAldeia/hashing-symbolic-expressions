{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tevals\tn_simplifications\tn_new_hashes\tavg train error\tavg train size\tavg val error\tavg val size\tmed train error\tmed train size\tmed val error\tmed val size\tstd train error\tstd train size\tstd val error\tstd val size\tmin train error\tmin train size\tmin val error\tmin val size\tmax train error\tmax train size\tmax val error\tmax val size\n",
      "0  \t20   \t0                \t0           \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \n",
      "1  \t20   \t0                \t0           \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \n",
      "2  \t20   \t0                \t0           \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \n",
      "3  \t20   \t0                \t0           \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \n",
      "4  \t20   \t0                \t0           \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \n",
      "5  \t20   \t0                \t0           \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \n",
      "6  \t20   \t0                \t0           \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \n",
      "7  \t20   \t0                \t0           \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \n",
      "8  \t20   \t0                \t0           \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \n",
      "9  \t20   \t0                \t0           \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \t               \t              \t             \t            \n",
      "best model subtract(mul3(log1p(9356416.40821584), x_5, x_3), x_2) with size 7,  depth 3,  and fitness (146.1618212597714, 7.0)\n"
     ]
    }
   ],
   "source": [
    "from nsga2.estimator import NSGAIIRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('../data/lexicase_paper/d_yacht.txt', sep=',')\n",
    "\n",
    "# DEAP interface requires X and y to be numpy arrays, not pandas dataframes\n",
    "X = df.drop('label', axis=1).values\n",
    "y = df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "estimator = NSGAIIRegressor(**{\n",
    "    'pop_size'        : 20, \n",
    "    'max_gen'         : 10,\n",
    "    'max_depth'       : 10,  # 8\n",
    "    'max_size'        : 100, # 75\n",
    "    'objectives'      : ['error', 'size'],\n",
    "    'cx_prob'         : 1/7,\n",
    "    'initialization'  : 'uniform',\n",
    "    'pick_criteria'   : 'MCDM', # error, MCDM\n",
    "    'validation_size' : 0.33,\n",
    "    'simplify'        : False,\n",
    "    'verbosity'       : 1,\n",
    "}).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subtract(mul3(log1p(9356416.40821584), x_5, x_3), x_2)\n",
      "7\n",
      "7\n",
      "3\n",
      "train_r2 : -1.5991588476733338\n",
      "test_r2 : -2.3678095431141295\n",
      "train_mse : 130.8999408591487\n",
      "test_mse : 128.30055076930336\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "model      = str(estimator.best_estimator_).replace(\"ARG\", \"x_\")\n",
    "size       = len(estimator.best_estimator_)\n",
    "complexity = size\n",
    "depth      = estimator.best_estimator_.height\n",
    "\n",
    "print(model)\n",
    "print(size)\n",
    "print(complexity)\n",
    "print(depth)\n",
    "\n",
    "for metric, fn, (data_X, data_y) in [\n",
    "    ('train_r2',  r2_score, (X_train, y_train)),\n",
    "    ('test_r2',   r2_score, (X_test,  y_test )),\n",
    "    ('train_mse', mse,      (X_train, y_train)),\n",
    "    ('test_mse',  mse,      (X_test,  y_test )),\n",
    "]:\n",
    "    score = np.nan\n",
    "    try:\n",
    "        score = fn(estimator.predict(data_X), data_y)\n",
    "        print(f\"{metric} : {score}\")\n",
    "    except ValueError:\n",
    "        print(f\"(Failed to calculate {metric}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hashing-experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
